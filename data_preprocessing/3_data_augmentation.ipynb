{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda373ed",
   "metadata": {},
   "source": [
    "# Data Augmentation for Processing in ASR\n",
    "\n",
    "## Team: AI-NLP \n",
    "\n",
    "Author: Aline Rodrigues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f48cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation():\n",
    "    \"\"\"\n",
    "        Author:  Aline Rodrigues\n",
    "        Created: 01/11/2024\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: str =''):        \n",
    "        self.dataset = dataset\n",
    "    \n",
    "    \n",
    "    def load_audio(self, file_path: str, sr=16000):\n",
    "        audio, sample_rate = librosa.load(file_path, sr=sr)\n",
    "        return audio, sample_rate\n",
    "\n",
    "\n",
    "    def save_audio(self, file_path, audio, sample_rate):\n",
    "        sf.write(file_path, audio, sample_rate)\n",
    "\n",
    "\n",
    "    def time_stretch(self, audio, sr, rate=1.2):\n",
    "        return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "    def pitch_shift(self, audio, sr, n_steps=4):\n",
    "        return librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "    def add_noise(self, audio, sr, noise_factor=0.005):\n",
    "        noise = np.random.randn(len(audio))\n",
    "        augmented_audio = audio + noise_factor * noise\n",
    "        return augmented_audio\n",
    "\n",
    "    def apply_rir(self, audio, sr, rir):\n",
    "        return np.convolve(audio, rir, mode='full')[:len(audio)]\n",
    "\n",
    "    def generate_synthetic_rir(self, length=200):\n",
    "        rir = np.random.normal(0, 1, length)\n",
    "        rir = rir / np.linalg.norm(rir)  # Normalizar para manter a energia original\n",
    "        return rir\n",
    "    \n",
    "    def spec_augment(self, spec, time_warping=80, freq_masking=27, time_masking=100):\n",
    "        # Time Warping\n",
    "        if random.random() > 0.5:  # 50% de chance de aplicar\n",
    "            time_shift = random.randint(-time_warping, time_warping)\n",
    "            spec = torch.roll(spec, shifts=time_shift, dims=-1)\n",
    "        \n",
    "        # Frequency Masking\n",
    "        num_freqs = spec.size(0)  # Número de bins de frequência\n",
    "        if freq_masking < num_freqs:\n",
    "            freq_size = random.randint(0, min(freq_masking, num_freqs))  # Limite para freq_masking\n",
    "            freq_start = random.randint(0, num_freqs - freq_size)\n",
    "            spec[freq_start:freq_start + freq_size, :] = 0\n",
    "        \n",
    "        # Time Masking\n",
    "        num_times = spec.size(1)  # Número de frames de tempo\n",
    "        if time_masking < num_times:\n",
    "            time_size = random.randint(0, min(time_masking, num_times))  # Limite para time_masking\n",
    "            time_start = random.randint(0, num_times - time_size)\n",
    "            spec[:, time_start:time_start + time_size] = 0\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def spectrogram_to_waveform(self, spectrogram, n_iter=32):\n",
    "        # Inversão do espectrograma usando Griffin-Lim\n",
    "        griffin_lim = torchaudio.transforms.GriffinLim(n_fft=1024)\n",
    "        waveform = griffin_lim(spectrogram)\n",
    "        return waveform\n",
    "    \n",
    "\n",
    "    def augment_audio(self, audio, sr: int, output_path: str, alias: str, row: dict) -> dict:\n",
    "        rows = []\n",
    "        # 1. Time-Stretch\n",
    "        stretched_audio = self.time_stretch(audio, rate=0.95)\n",
    "        self.save_audio(f'{output_path}/{alias}_time_stretched.wav', stretched_audio, sr)\n",
    "        path = row['path'].replace(alias, f'{alias}_time_stretched')\n",
    "        row1 = row.copy()\n",
    "        row1['path'] = path\n",
    "        rows.append(row1)\n",
    "        # 2. Pitch Shifting\n",
    "        pitch_shifted_audio = self.pitch_shift(audio, sr, n_steps=1)\n",
    "        self.save_audio(f'{output_path}/{alias}_pitch_shifted.wav', pitch_shifted_audio, sr)\n",
    "        path = row['path'].replace(alias, f'{alias}_pitch_shifted')\n",
    "        row1 = row.copy()\n",
    "        row1['path'] = path\n",
    "        rows.append(row1)\n",
    "        # 3. Additive Noise\n",
    "        noisy_audio = self.add_noise(audio, noise_factor=0.005)\n",
    "        self.save_audio(f'{output_path}/{alias}_noisy.wav', noisy_audio, sr)\n",
    "        path = row['path'].replace(alias, f'{alias}_noisy')\n",
    "        row1 = row.copy()\n",
    "        row1['path'] = path\n",
    "        rows.append(row1)\n",
    "        # 4. Room Impulse Response (RIR)\n",
    "        rir = self.generate_synthetic_rir(length=300)\n",
    "        rir_audio = self.apply_rir(audio, rir)\n",
    "        self.save_audio(f'{output_path}/{alias}_rir_applied.wav', rir_audio, sr)\n",
    "        path = row['path'].replace(alias, f'{alias}_rir_applied')\n",
    "        row1 = row.copy()\n",
    "        row1['path'] = path\n",
    "        rows.append(row1)\n",
    "        return rows\n",
    "    \n",
    "    \n",
    "    def apply_augmentations(self, row, audio, sr, output_path, alias):\n",
    "        \"\"\"\n",
    "        Aplica até 2 augmentations aleatórias por áudio.\n",
    "        \"\"\"\n",
    "        techniques = [\n",
    "            (\"time_stretch\", self.time_stretch, {\"rate\": random.uniform(0.95, 1.05)}),\n",
    "            (\"pitch_shift\", self.pitch_shift, {\"n_steps\": random.choice([-1, 1])}),\n",
    "            (\"add_noise\", self.add_noise, {\"noise_factor\": 0.005}),\n",
    "            (\"rir\", self.apply_rir, {\"rir\": self.generate_synthetic_rir(length=300)}),\n",
    "        ]\n",
    "\n",
    "        selected = random.sample(techniques, k=2)  # aplica 2 augmentations diferentes\n",
    "\n",
    "        rows = []\n",
    "        for name, func, kwargs in selected:\n",
    "            try:\n",
    "                augmented_audio = func(audio, sr=sr, **kwargs)\n",
    "                filename = f'{alias}_{name}.wav'\n",
    "                self.save_audio(f'{output_path}/{filename}', augmented_audio, sr)\n",
    "\n",
    "                row1 = row.copy()\n",
    "                row1['path'] = row['path'].replace(alias, filename[:-4])  # remove \".wav\"\n",
    "                rows.append(row1)\n",
    "            except Exception as e:\n",
    "                print(f\"[!] Falha ao aplicar {name}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return rows\n",
    "\n",
    "    def run(self):        \n",
    "        # load data\n",
    "        df = pd.read_csv(self.dataset + 'train.csv',  encoding='utf-8')\n",
    "        \n",
    "        df_aug = []\n",
    "        path_audios = self.dataset + 'train/'\n",
    "        output_dir = self.dataset + 'aug/'\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            \n",
    "            path_audio = path_audios + row['path']\n",
    "            print(path_audio)\n",
    "            alias = path_audio.split('/')[-1].replace('.wav', '')\n",
    "        \n",
    "            audio, sr = self.load_audio(path_audio)\n",
    "            rows = self.apply_augmentations(row.copy(), audio, sr, output_dir, alias)\n",
    "            df_aug.extend(rows)\n",
    "            \n",
    "        df_aug = pd.DataFrame(df_aug)\n",
    "        concatenated_df = pd.concat([df, df_aug], axis=0)\n",
    "        concatenated_df.to_csv('data_augmentation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "DataAugmentation(dataset).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
